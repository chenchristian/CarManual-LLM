import base64
import requests # For fetching image from URL if needed
import os
from openai import OpenAI
from dotenv import load_dotenv
import config # +
import logging # +

# + Configure logging (similar to main.py, but could be a shared utility)
# + if not os.path.exists(config.LOG_DIR):
# +     os.makedirs(config.LOG_DIR)
# + logging.basicConfig(level=config.LOG_LEVEL, format=config.LOG_FORMAT)
# + logger = logging.getLogger(__name__)
# + file_handler = logging.FileHandler(os.path.join(config.LOG_DIR, 'vision_analyzer.log')) # Specific log for this module
# + file_handler.setFormatter(logging.Formatter(config.LOG_FORMAT))
# + logger.addHandler(file_handler)

# Simplified logging setup for this module, assuming main.py's setup might cover basicConfig
logger = logging.getLogger(__name__) # +
# If running standalone and not via main.py, basicConfig might be needed here too.
# For now, assume it's part of the larger app context or run after main.py initializes logging.

# Load environment variables, especially OPENAI_API_KEY
load_dotenv()

# Initialize OpenAI client
# Ensure OPENAI_API_KEY is set in your .env or system environment
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# Specify the GPT-4 Vision model - REMOVED, will use config.VISION_MODEL_ID
# GPT_4_VISION_MODEL = "gpt-4.1-mini" 

def encode_image_to_base64(image_path: str) -> str:
    """Encodes a local image file to a base64 string."""
    try:
        with open(image_path, "rb") as image_file:
            return base64.b64encode(image_file.read()).decode('utf-8')
    except Exception as e:
        logger.error(f"Error encoding image {image_path} to base64: {e}", exc_info=True) # Modified
        raise

def get_image_description_from_gpt4v(
    image_path_or_url: str,
    prompt: str,
    max_tokens: int = 300
) -> str:
    """
    Gets a description of an image using GPT-4 Vision.
    The image can be a local path or a publicly accessible URL.

    Args:
        image_path_or_url (str): The local path to the image or its public URL.
        prompt (str): The prompt to send to the model along with the image.
        max_tokens (int): The maximum number of tokens for the response.

    Returns:
        str: The description generated by the model.

    Raises:
        Exception: If the API call fails or the image cannot be processed.
    """
    image_content = []

    if image_path_or_url.startswith(("http://", "https://")):
        image_content.append({
            "type": "image_url",
            "image_url": {"url": image_path_or_url}
        })
        logger.info(f"Sending image URL to GPT-4V: {image_path_or_url}") # Modified
    else:
        try:
            base64_image = encode_image_to_base64(image_path_or_url)
            mime_type = "image/jpeg" 
            if image_path_or_url.lower().endswith(".png"):
                mime_type = "image/png"
            elif image_path_or_url.lower().endswith(".gif"):
                mime_type = "image/gif"
            elif image_path_or_url.lower().endswith(".webp"):
                mime_type = "image/webp"
            
            image_content.append({
                "type": "image_url",
                "image_url": {"url": f"data:{mime_type};base64,{base64_image}"}
            })
            logger.info(f"Sending base64 encoded image to GPT-4V: {image_path_or_url}") # Modified
        except Exception as e:
            logger.error(f"Failed to process local image {image_path_or_url}: {e}", exc_info=True) # Modified
            raise

    try:
        messages_payload = [
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": prompt}
                ] + image_content 
            }
        ]
        
        logger.info(f"Sending prompt to GPT-4V ('{config.VISION_MODEL_ID}'): '{prompt[:100]}...'") # Modified

        response = client.chat.completions.create(
            model=config.VISION_MODEL_ID, # Modified
            messages=messages_payload,
            max_tokens=max_tokens
        )
        
        if response.choices and response.choices[0].message and response.choices[0].message.content:
            description = response.choices[0].message.content
            logger.info("Received description from GPT-4V.") # Modified
            return description
        else:
            logger.error("GPT-4V returned no content or an unexpected response structure.") # Modified
            raise Exception("Failed to get a valid description from GPT-4V: No content in response")

    except Exception as e:
        logger.error(f"Error calling GPT-4 Vision API ('{config.VISION_MODEL_ID}'): {e}", exc_info=True) # Modified
        raise 

if __name__ == '__main__':
    # This basicConfig is for standalone testing of this script.
    # When imported into main.py, main.py's logging config will likely apply.
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')

    if not os.path.exists("test_image.jpg"):
        with open("test_image.jpg", "w") as f:
            f.write("This is a dummy image file for testing vision_analyzer.py.")
        logger.info("Created a dummy test_image.jpg for example usage.") # Modified

    test_image_path = "test_image.jpg" 
    test_prompt = "What is in this image? If it's a car dashboard, describe any warning lights."
    
    logger.info("\n--- Running vision_analyzer.py example ---") # Modified
    try:
        if os.path.exists(test_image_path):
            logger.info(f"\nTesting with local file: {test_image_path}") # Modified
            description = get_image_description_from_gpt4v(test_image_path, test_prompt)
            logger.info(f"\nGPT-4V (local image) Description:\n{description}") # Modified
        else:
            logger.warning(f"Skipping local image test, file not found: {test_image_path}") # Modified

        test_image_url = "https://www.publicdomainpictures.net/pictures/20000/nahled/series-of-warning-lights-on-dashboard.jpg" 
        logger.info(f"\nTesting with image URL: {test_image_url}") # Modified
        try:
            url_description = get_image_description_from_gpt4v(test_image_url, "What car dashboard symbol is this?")
            logger.info(f"\nGPT-4V (URL image) Description:\n{url_description}") # Modified
        except requests.exceptions.RequestException as req_ex:
            logger.error(f"Could not fetch image from URL {test_image_url}: {req_ex}. Skipping URL test.", exc_info=True) # Modified
        except Exception as url_ex:
            logger.error(f"Error during URL image test ({test_image_url}): {url_ex}", exc_info=True) # Modified

    except Exception as e:
        logger.error(f"An error occurred during the example run: {e}", exc_info=True) # Modified
    finally:
        if os.path.exists("test_image.jpg") and "dummy image file" in open("test_image.jpg").read():
            logger.info(f"Note: Dummy file test_image.jpg was used. You might want to remove it or replace with a real image for further tests.") # Modified
        logger.info("--- Finished vision_analyzer.py example ---") # Modified 